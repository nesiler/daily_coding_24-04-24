## Problem - Go ile Web Scraping

Bu senaryoda, **Go** ve Go dilinde Ã§ok tercih edilen scraping kÃ¼tÃ¼phanesi **"gocolly/colly"** kullanarak **"[books.toscrape](https://books.toscrape.com/)"** web sitesinden veri kazÄ±ma (web scraping) yapacaÄŸÄ±z.

>Bu senaryo sadece eÄŸitim amaÃ§lÄ±dÄ±r. Web sitesi sahibinin izni olmadan web sitesinden veri kazÄ±mak yasa dÄ±ÅŸÄ± olabilir. Bizim Ã¶rneÄŸimizde, [books.toscrape](https://books.toscrape.com/) sitesi tamamen test amaÃ§lÄ± oluÅŸturulmuÅŸ bir site olduÄŸu iÃ§in bu siteyi kullanÄ±yoruz.

### ğŸ› ï¸ Gerekli OrtamlarÄ±n AyarlanmasÄ± ğŸ› ï¸

Ã–ncelikle, bir klasÃ¶r ve iÃ§erisine `main.go` adÄ±nda bir dosya oluÅŸturalÄ±m.

```bash
mkdir book-scraper && cd book-scraper
touch main.go
```

Sistemde Go yÃ¼klÃ¼yse, gerekli paketi yÃ¼klemek iÃ§in terminalde aÅŸaÄŸÄ±daki komutu Ã§alÄ±ÅŸtÄ±rabiliriz:
```bash
go get -u github.com/gocolly/colly
```

Go yÃ¼klÃ¼ deÄŸilse, Alpine Linux iÃ§in aÅŸaÄŸÄ±daki komutu Ã§alÄ±ÅŸtÄ±rarak Go'yu yÃ¼kledikten sonra yukarÄ±daki komutu Ã§alÄ±ÅŸtÄ±rabiliriz:
```bash
apk add go
```

### ğŸš€ Uygulama AdÄ±mlarÄ± ğŸš€
AÅŸaÄŸÄ±daki kodu `main.go` dosyasÄ±na yapÄ±ÅŸtÄ±rarak ilk aÅŸamayÄ± tamamlayabiliriz.
```go
package main

import (
    "fmt"
    "github.com/gocolly/colly"
)

func main() {
    // Colly instance
    collector := colly.NewCollector(
        colly.AllowedDomains("books.toscrape.com"),
    )

    // On HTML element callback
    collector.OnHTML("h3", func(element *colly.HTMLElement) {
        bookTitle := element.Text
        fmt.Println("Kitap AdÄ±:", bookTitle)
    })

    // Start scraping
    collector.Visit("https://books.toscrape.com/")
}
```

**AÃ§Ä±klama:**
  `main` fonksiyonu iÃ§erisinde:
    * `colly.NewCollector` fonksiyonu ile bir `colly` nesnesi oluÅŸturuyoruz.
    * `colly.AllowedDomains` fonksiyonu ile scraping yapÄ±lacak alan adÄ±nÄ± ("books.toscrape.com") belirliyoruz.
    * `OnHTML` fonksiyonu ile HTML Ã¶ÄŸelerine (h3 etiketleri) rastlandÄ±ÄŸÄ±nda tetiklenecek bir callback fonksiyonu tanÄ±mlÄ±yoruz.
        * Bu callback fonksiyonu iÃ§erisinde, `element.Text` ile h3 etiketinin iÃ§eriÄŸini (kitap adÄ±nÄ±) alÄ±yoruz ve ekrana yazdÄ±rÄ±yoruz.
    * `Visit` fonksiyonu ile scraping iÅŸlemini baÅŸlatÄ±yoruz.


### â–¶ï¸ Kodu Ã‡alÄ±ÅŸtÄ±rma â–¶ï¸
Kodu Ã§alÄ±ÅŸtÄ±rdÄ±ktan sonra ilk Ã§Ä±ktÄ±da kitap adlarÄ±nÄ± gÃ¶rebiliriz.
**Ã‡Ä±ktÄ±:**
```
Kitap AdÄ±: A Light in the ...
Kitap AdÄ±: Tipping the Velvet
Kitap AdÄ±: Soumission
Kitap AdÄ±: Sharp Objects
...
```

**Buraya kadar baÅŸarÄ±yla tamamladÄ±ysanÄ±z ÅŸimdi biraz daha karmaÅŸÄ±k bir Ã¶rnek yapalÄ±m. Bu sefer kitap adÄ±, fiyat ve resim bilgilerini alÄ±p bir dosyaya yazdÄ±ralÄ±m.**

### Hangi Verileri KazÄ±yacaÄŸÄ±z?
Veri kazÄ±ma iÅŸlemi yaparken, ilgili web sitesini ziyaret edip hangi verileri kazÄ±yacaÄŸÄ±mÄ±za karar vermemiz ve verilerin `html` yapÄ±sÄ±nÄ± incelememiz gerekmektedir.

![](scraper_ss.png)

YukarÄ±daki resimde de gÃ¶rÃ¼ldÃ¼ÄŸÃ¼ gibi, sayfaya saÄŸ tÄ±klayÄ±p "Inspect" seÃ§eneÄŸine tÄ±kladÄ±ÄŸÄ±mÄ±zda, sayfanÄ±n `html` yapÄ±sÄ±nÄ± inceleyebiliriz. 
Ok ile belirtilen araÃ§, istediÄŸimiz veriye tÄ±klayarak detaylÄ± bilgiye ulaÅŸmamÄ±zÄ± saÄŸlar. 
Yine yeÅŸil ile belirtilen alanda hangi elementin hangi tag altÄ±nda olduÄŸunu gÃ¶rebiliriz.

Bizim kullanacaÄŸÄ±mÄ±z verilerin yapÄ±sÄ± ÅŸu ÅŸekilde:
* BaÅŸlÄ±k: h3
* Fiyat: price_color
* Resim URL: img->src (child attribute)

### ğŸ‘©ğŸ»â€ğŸ’» Kodlamaya Devam ğŸ‘¨ğŸ»â€ğŸ’»

Bu sefer dosyaya yazma iÅŸlemi de yapacaÄŸÄ±z. Bu yÃ¼zden Ã¶ncelikle "os" paketini import ediyoruz.
```go
import (
    ...
	"os"
)
```

Hemen altÄ±na kitap verilerini tutacak olan `Book` struct'Ä±nÄ± oluÅŸturuyoruz.
```go
type Book struct {
    Title string
    Price string
    ImageURL string
}
```

`main` fonksiyonunun en baÅŸÄ±na aÅŸaÄŸÄ±daki kodu ekliyoruz. Bu kod, `kitap_verileri.txt` adÄ±nda bir dosya oluÅŸturacak.
```go
	// Create a file
    file, err := os.Create("kitap_verileri.txt")
    if err != nil {
        fmt.Println("Dosya oluÅŸturulamadÄ±:", err)
        return
    }
    defer file.Close()

	// Colly instance...
```

Colly instance oluÅŸturduktan hemen sonra `OnHTML` fonksiyonunu aÅŸaÄŸÄ±daki gibi gÃ¼ncelliyoruz.
```go
	// On HTML element callback
	collector.OnHTML(".product_pod", func(element *colly.HTMLElement) {
		book := Book{}

		book.Title = element.ChildText("h3 a")
		book.Price = element.ChildText(".price_color")
		book.ImageURL = element.ChildAttr("img", "src")

		line := fmt.Sprintf("Kitap AdÄ±: %s\nFiyat: %s\nResim URL: %s\n\n", book.Title, book.Price, book.ImageURL)
		fmt.Println(line)

		// Dosyaya yazma iÅŸlemi
		_, err := file.WriteString(line)
		if err != nil {
			fmt.Println("Dosyaya yazma hatasÄ±:", err)
		}
	})
```

**AÃ§Ä±klama:**
`main` fonksiyonu iÃ§erisinde:
    * `Book` adÄ±nda bir struct oluÅŸturuyoruz. Bu struct, kazÄ±nacak verileri (kitap adÄ±, fiyat, resim URL'si) saklayacak.
    * `OnHTML` fonksiyonu ile HTML Ã¶ÄŸelerine (`.product_pod` sÄ±nÄ±fÄ±) rastlandÄ±ÄŸÄ±nda tetiklenecek bir callback fonksiyonu tanÄ±mlÄ±yoruz.
        * Bu callback fonksiyonu iÃ§erisinde:
            * `element.ChildText` ve `element.ChildAttr` fonksiyonlarÄ±nÄ± kullanarak `.product_pod` Ã¶ÄŸesinin altÄ±ndaki h3 etiketi, `.price_color` sÄ±nÄ±fÄ± ve `img` etiketi ile iliÅŸkili verileri (`book.Title`, `book.Price`, `book.ImageURL`) alÄ±yoruz.
            * AlÄ±nan verileri formatlÄ± bir ÅŸekilde ekrana yazdÄ±rÄ±yoruz.

### SonuÃ§
Kodu Ã§alÄ±ÅŸtÄ±rdÄ±ktan sonra, eÄŸer tÃ¼m adÄ±mlar baÅŸarÄ±yla tamamlandÄ±ysa, `kitap_verileri.txt` dosyasÄ±nda kitap adÄ±, fiyat ve resim URL'si bilgilerini gÃ¶rebiliriz.

**Ã‡Ä±ktÄ±:**

```
Kitap AdÄ±: A Light in the ...
Fiyat: Â£51.77
Resim URL: media/cache/2c/da/2cdad67c44b002e7ead0cc35693c0e8b.jpg
...
```